# Batched NTT Implementation Plan - Phase 1

## Status: âœ… COMPLETE - Ready for Testing on RTX 5090!

### Completed
1. âœ… **Batched CUDA Kernels Created** (ntt.cu)
   - `ntt_forward_batched` - Process all primes in parallel
   - `ntt_inverse_batched` - Process all primes in parallel
   - `ntt_pointwise_multiply_batched` - Process all primes in parallel
   - Uses 2D grid: (butterfly_blocks, num_primes)

2. âœ… **Kernels Compile Successfully**
   - Verified with `cargo build`
   - No CUDA compilation errors

3. âœ… **Batched NTT Kernels Loaded**
   - Updated ntt.rs to load batched kernel names
   - Made twiddles, twiddles_inv, n_inv, device accessible

4. âœ… **Batched NTT Wrapper Methods Implemented** (ckks.rs)
   - `ntt_forward_batched()` - 3 batched wrapper methods added
   - `ntt_inverse_batched()` - Handles twiddle collection
   - `ntt_pointwise_multiply_batched()` - 2D grid launch configuration

5. âœ… **multiply_ciphertexts_tensored Updated**
   - Replaced sequential per-prime loop with batched operations
   - Reduced from 240 â†’ 13 kernel launches per multiplication
   - Complete rewrite with clear documentation

6. âœ… **Full Compilation Success**
   - Library: âœ… Compiles in 8.98s
   - Example: âœ… Compiles in 14.32s
   - Zero errors, zero warnings

### Testing on RTX 5090

**Run the following command:**
```bash
cargo run --release --features v2,v2-gpu-cuda,v3 --example test_cuda_bootstrap
```

**Expected improvements:**
- âœ… Kernel launch count reduction: 24,800 â†’ 1,240 per BSGS (20Ã—)
- ðŸŽ¯ EvalMod time target: < 13s (down from 14.42s)
- ðŸš€ Bootstrap time target: < 13s total

**What to verify:**
1. Correctness: Bootstrap completes successfully without errors
2. Performance: Measure actual EvalMod time improvement
3. GPU utilization: Should be higher with batched operations
4. Kernel launch overhead: ~470ms reduction expected

### Implementation Details

#### Kernel Launch Configuration (2D Grid)

For batched operations:
```rust
let threads_per_block = 256;
let num_butterfly_blocks = (n / 2 + threads_per_block - 1) / threads_per_block;

let cfg = LaunchConfig {
    grid_dim: (num_butterfly_blocks as u32, num_primes as u32, 1),  // 2D!
    block_dim: (threads_per_block as u32, 1, 1),
    shared_mem_bytes: 0,
};
```

#### Data Preparation

Need to prepare twiddles and moduli for all primes:
```rust
// Collect all twiddles into single buffer
let mut all_twiddles = Vec::with_capacity(n * num_primes);
let mut all_moduli = Vec::with_capacity(num_primes);

for prime_idx in 0..num_primes {
    let ntt_ctx = &self.ntt_contexts[prime_idx];
    all_twiddles.extend_from_slice(&ntt_ctx.twiddles);
    all_moduli.push(ntt_ctx.q);
}
```

### Expected Performance Impact

**Current multiply_ciphertexts_tensored**:
- NTT stages per prime: logâ‚‚(32768) = 15 stages
- Kernel launches: 4 forward Ã— 15 stages Ã— 20 primes = 1,200
- Plus 4 pointwise Ã— 20 = 80
- Plus 4 inverse Ã— 15 stages Ã— 20 = 1,200
- **Total: ~2,480 launches per multiplication**

**Batched multiply_ciphertexts_tensored**:
- Forward NTT: 4 polynomials Ã— 15 stages = 60 launches
- Pointwise: 4 operations Ã— 1 launch = 4 launches
- Inverse NTT: 4 polynomials Ã— 15 stages = 60 launches
- **Total: ~124 launches per multiplication (20Ã— reduction!)**

**BSGS Impact** (10 multiplications):
- Current: 10 Ã— 2,480 = 24,800 launches
- Batched: 10 Ã— 124 = 1,240 launches
- **Reduction: 24,800 â†’ 1,240 (20Ã— fewer)**

**Expected time savings**:
- Launch overhead reduced: 24,800 Ã— 20Î¼s = 496ms â†’ 1,240 Ã— 20Î¼s = 25ms
- **Overhead reduction: ~470ms saved**
- Plus better GPU utilization â†’ **estimated 1-2s total speedup**
- **Target EvalMod time: 12-13s** (down from 14.4s)

### Testing Plan

1. **Unit Test**: Single multiplication with batched NTT
   - Verify correctness vs sequential version
   - Measure kernel launch count

2. **Performance Test**: BSGS polynomial evaluation
   - Compare old vs new `multiply_ciphertexts_tensored`
   - Profile with `nvprof` or Nsight Compute
   - Measure actual kernel launch reduction

3. **Full Bootstrap Test**: Complete V3 CUDA bootstrap
   - Target: < 13s bootstrap time
   - Verify numerical correctness
   - Check GPU utilization increased

### Risk Assessment

**Low Risk**:
- Kernel logic identical to sequential version
- Only difference is 2D grid instead of loop
- Easy to rollback if issues

**Potential Issues**:
- Grid size limits (max 65535 blocks per dimension)
  - Not a problem: num_primes â‰¤ 30, butterflies â‰¤ 16384
- Shared memory conflicts
  - Not applicable: no shared memory used
- Synchronization bugs
  - Not applicable: primes are independent

### Success Criteria

âœ… **Minimum Success**:
- Batched NTT produces identical results
- At least 10Ã— reduction in kernel launches
- EvalMod time < 13.5s

ðŸŽ¯ **Target Success**:
- 20Ã— reduction in kernel launches
- EvalMod time < 13s
- Measurably improved GPU utilization

ðŸš€ **Stretch Goal**:
- Consider fusing NTT stages (Phase 2)
- EvalMod time < 12s
- Path to sub-10s bootstrap

---

## Next Session Tasks

1. Implement batched NTT wrapper methods in `ckks.rs`
2. Update `multiply_ciphertexts_tensored` to use batched operations
3. Compile and test on RTX 5090
4. Profile and measure performance improvements
5. Document results and plan Phase 2 (fusion)

---

**Document Version**: 1.0
**Last Updated**: 2025-01-09
**Author**: Claude & David Silva
