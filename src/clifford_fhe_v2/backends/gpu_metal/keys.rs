//! Metal GPU-Accelerated Key Generation for V2/V3
//!
//! **Performance Target:**
//! - CPU (N=8192, 20 primes): 5-10 minutes
//! - Metal GPU (N=8192, 20 primes): <10 seconds (30-60× speedup)
//!
//! **Key Optimizations:**
//! - GPU NTT context creation (twiddle factor precomputation)
//! - GPU polynomial multiplication during key generation
//! - Unified memory architecture (zero-copy on Apple Silicon)
//!
//! **Architecture:**
//! ```
//! CPU Side:                          GPU Side (Metal):
//! - Random sampling (s, a, e)        → Upload to GPU
//! - Control flow                     → NTT operations
//!                                    → Polynomial multiplication
//!                                    → Download results
//! ```

use super::device::MetalDevice;
use super::ntt::MetalNttContext;
use crate::clifford_fhe_v2::backends::cpu_optimized::keys::{PublicKey, SecretKey, EvaluationKey};
use crate::clifford_fhe_v2::backends::cpu_optimized::rns::{BarrettReducer, RnsRepresentation};
use crate::clifford_fhe_v2::params::CliffordFHEParams;
use rand::distributions::Distribution;
use rand::{Rng, SeedableRng};
use rand_chacha::ChaCha20Rng;
use rand_distr::Normal;
use std::sync::Arc;

/// Metal GPU-Accelerated Key Context
///
/// Drop-in replacement for CPU KeyContext but uses Metal GPU for NTT operations.
///
/// # Example
///
/// ```rust,ignore
/// let params = CliffordFHEParams::new_v3_bootstrap_8192();
/// let key_ctx = MetalKeyContext::new(params)?;
/// let (pk, sk, evk) = key_ctx.keygen();  // <10 seconds on Metal GPU
/// ```
pub struct MetalKeyContext {
    /// FHE parameters
    pub params: CliffordFHEParams,

    /// Metal device (shared across all NTT contexts)
    device: Arc<MetalDevice>,

    /// Metal NTT contexts for each prime
    ntt_contexts: Vec<MetalNttContext>,

    /// Barrett reducers for each prime (CPU-side, very cheap)
    reducers: Vec<BarrettReducer>,

    /// Thread-local RNG for sampling
    rng: ChaCha20Rng,
}

impl MetalKeyContext {
    /// Create new Metal key context with GPU-accelerated NTT
    ///
    /// **This is where the magic happens**: NTT contexts are created in parallel on CPU,
    /// but the Metal device is shared across all of them for actual NTT operations.
    ///
    /// # Performance
    ///
    /// - N=8192, 20 primes: ~2-5 seconds (vs 30-60 seconds on CPU)
    /// - N=16384, 25 primes: ~5-10 seconds (vs 2-5 minutes on CPU)
    pub fn new(params: CliffordFHEParams) -> Result<Self, String> {
        let moduli = params.moduli.clone();

        println!("  [Metal GPU] Creating Metal device...");
        let start = std::time::Instant::now();
        let device = Arc::new(MetalDevice::new()?);
        println!("  [Metal GPU] Device initialized in {:.3}s", start.elapsed().as_secs_f64());

        println!("  [Metal GPU] Creating NTT contexts for {} primes...", moduli.len());
        let start = std::time::Instant::now();

        // Create Metal NTT contexts (twiddle factors computed on CPU, but operations run on GPU)
        // We share the Metal device across all contexts to avoid creating multiple GPU connections
        let mut ntt_contexts = Vec::with_capacity(moduli.len());
        for (i, &q) in moduli.iter().enumerate() {
            eprintln!("  [Metal GPU] Creating NTT context {}/{} for q={}...", i+1, moduli.len(), q);
            // Find primitive 2n-th root of unity (psi)
            eprintln!("    Finding primitive root...");
            let psi = Self::find_primitive_2n_root(params.n, q)?;
            eprintln!("    Found psi={}, creating Metal NTT context...", psi);
            // Pass psi (not omega) to MetalNttContext for twisted NTT
            // The NTT context will compute omega = psi^2 internally
            let metal_ntt = MetalNttContext::new_with_device(device.clone(), params.n, q, psi)?;
            eprintln!("    Metal NTT context {} created!", i+1);
            ntt_contexts.push(metal_ntt);
        }

        println!("  [Metal GPU] NTT contexts created in {:.2}s", start.elapsed().as_secs_f64());

        // Barrett reducers (CPU-side, cheap)
        let reducers: Vec<BarrettReducer> = moduli
            .iter()
            .map(|&q| BarrettReducer::new(q))
            .collect();

        // Create RNG for sampling
        let mut seed = [0u8; 32];
        rand::thread_rng().fill(&mut seed);
        let rng = ChaCha20Rng::from_seed(seed);

        Ok(Self {
            params,
            device,
            ntt_contexts,
            reducers,
            rng,
        })
    }

    /// Generate secret, public, and evaluation keys
    ///
    /// # Returns
    ///
    /// Result<(PublicKey, SecretKey, EvaluationKey), String>
    ///
    /// # Performance
    ///
    /// - N=8192, 20 primes: <10 seconds (vs 5-10 minutes CPU)
    pub fn keygen(&mut self) -> Result<(PublicKey, SecretKey, EvaluationKey), String> {
        use std::time::Instant;

        let n = self.params.n;
        let level = self.params.max_level();
        let moduli: Vec<u64> = self.params.moduli[..=level].to_vec();

        println!("  [Metal GPU] Starting keygen for N={}, {} primes", n, moduli.len());

        // 1. Sample ternary secret key s ∈ {-1, 0, 1}^N (CPU)
        let start = Instant::now();
        let sk = self.sample_ternary_secret_key(&moduli);
        println!("  [Metal GPU] Step 1/5: Secret key sampled in {:.2}s", start.elapsed().as_secs_f64());

        // 2. Sample uniform random polynomial a (CPU)
        let start = Instant::now();
        let a = self.sample_uniform(&moduli);
        println!("  [Metal GPU] Step 2/5: Uniform poly sampled in {:.2}s", start.elapsed().as_secs_f64());

        // 3. Sample error polynomial e from Gaussian distribution (CPU)
        let start = Instant::now();
        let e = self.sample_error(&moduli);
        println!("  [Metal GPU] Step 3/5: Error poly sampled in {:.2}s", start.elapsed().as_secs_f64());

        // 4. Compute b = -a*s + e using GPU NTT multiplication
        let start = Instant::now();
        let a_times_s = self.multiply_polynomials_gpu(&a, &sk.coeffs, &moduli)?;
        let neg_a_times_s = self.negate_polynomial(&a_times_s, &moduli);
        let b = self.add_polynomials(&neg_a_times_s, &e);
        println!("  [Metal GPU] Step 4/5: Public key computed in {:.2}s", start.elapsed().as_secs_f64());

        let pk = PublicKey::new(a, b, level);

        // 5. Generate evaluation key for relinearization (uses GPU)
        println!("  [Metal GPU] Step 5/5: Starting evaluation key generation...");
        let start = Instant::now();
        let evk = self.generate_evaluation_key_gpu(&sk, &moduli)?;
        println!("  [Metal GPU] Step 5/5: Evaluation key generated in {:.2}s", start.elapsed().as_secs_f64());

        Ok((pk, sk, evk))
    }

    /// Sample ternary secret key: coefficients in {-1, 0, 1}
    fn sample_ternary_secret_key(&mut self, moduli: &[u64]) -> SecretKey {
        let n = self.params.n;
        let level = moduli.len() - 1;

        let coeffs: Vec<RnsRepresentation> = (0..n)
            .map(|_| {
                // Sample from {-1, 0, 1} with probability 1/3 each
                let val: i64 = match self.rng.gen_range(0..3) {
                    0 => -1,
                    1 => 0,
                    _ => 1,
                };

                // Convert to RNS representation
                let values: Vec<u64> = moduli
                    .iter()
                    .map(|&q| {
                        if val >= 0 {
                            val as u64
                        } else {
                            q - 1 // -1 mod q
                        }
                    })
                    .collect();

                RnsRepresentation::new(values, moduli.to_vec())
            })
            .collect();

        SecretKey::new(coeffs, level)
    }

    /// Sample uniform random polynomial from R_q
    fn sample_uniform(&mut self, moduli: &[u64]) -> Vec<RnsRepresentation> {
        let n = self.params.n;

        (0..n)
            .map(|_| {
                let values: Vec<u64> = moduli.iter().map(|&q| self.rng.gen_range(0..q)).collect();
                RnsRepresentation::new(values, moduli.to_vec())
            })
            .collect()
    }

    /// Sample error polynomial from Gaussian distribution χ
    fn sample_error(&mut self, moduli: &[u64]) -> Vec<RnsRepresentation> {
        let n = self.params.n;
        let error_std = self.params.error_std;

        let normal = Normal::new(0.0, error_std).expect("Invalid normal distribution");

        (0..n)
            .map(|_| {
                let error_val = normal.sample(&mut self.rng).round() as i64;

                let values: Vec<u64> = moduli
                    .iter()
                    .map(|&q| {
                        if error_val >= 0 {
                            (error_val as u64) % q
                        } else {
                            let abs_val = (-error_val) as u64;
                            let remainder = abs_val % q;
                            if remainder == 0 {
                                0
                            } else {
                                q - remainder
                            }
                        }
                    })
                    .collect();

                RnsRepresentation::new(values, moduli.to_vec())
            })
            .collect()
    }

    /// Multiply two polynomials using Metal GPU NTT
    ///
    /// This is the key performance optimization - all NTT operations run on GPU.
    /// Uses NEGACYCLIC convolution (mod x^n + 1) via twist/untwist, matching CPU implementation.
    fn multiply_polynomials_gpu(
        &self,
        a: &[RnsRepresentation],
        b: &[RnsRepresentation],
        moduli: &[u64],
    ) -> Result<Vec<RnsRepresentation>, String> {
        let n = self.params.n;

        // Result coefficients
        let mut result = Vec::with_capacity(n);

        // For each RNS component (prime), do NTT multiplication on GPU
        for (prime_idx, &q) in moduli.iter().enumerate() {
            // Extract coefficients for this prime
            let mut a_prime: Vec<u64> = a.iter().map(|rns| rns.values[prime_idx]).collect();
            let mut b_prime: Vec<u64> = b.iter().map(|rns| rns.values[prime_idx]).collect();

            let ntt_ctx = &self.ntt_contexts[prime_idx];

            // CRITICAL: Apply twist/untwist for negacyclic convolution (mod x^n + 1)
            // This matches CPU key generation and ensures consistency with CKKS ring structure

            // TWIST: multiply by psi^i (converts negacyclic → cyclic)
            let psi_powers = ntt_ctx.psi_powers();
            for i in 0..n {
                a_prime[i] = Self::mul_mod(a_prime[i], psi_powers[i], q);
                b_prime[i] = Self::mul_mod(b_prime[i], psi_powers[i], q);
            }

            // Forward NTT on GPU
            ntt_ctx.forward(&mut a_prime)?;
            ntt_ctx.forward(&mut b_prime)?;

            // Pointwise multiply on GPU
            let mut c_prime = vec![0u64; n];
            ntt_ctx.pointwise_multiply(&a_prime, &b_prime, &mut c_prime)?;

            // Inverse NTT on GPU
            ntt_ctx.inverse(&mut c_prime)?;

            // UNTWIST: multiply by psi^{-i} (converts cyclic → negacyclic)
            let psi_inv_powers = ntt_ctx.psi_inv_powers();
            for i in 0..n {
                c_prime[i] = Self::mul_mod(c_prime[i], psi_inv_powers[i], q);
            }

            // Store results
            if prime_idx == 0 {
                // Initialize result structure
                for i in 0..n {
                    result.push(RnsRepresentation::new(vec![c_prime[i]], vec![q]));
                }
            } else {
                // Append to existing RNS representation
                for i in 0..n {
                    result[i].values.push(c_prime[i]);
                    result[i].moduli.push(q);
                }
            }
        }

        Ok(result)
    }

    /// Generate evaluation key for relinearization (GPU-accelerated)
    fn generate_evaluation_key_gpu(
        &mut self,
        sk: &SecretKey,
        moduli: &[u64],
    ) -> Result<EvaluationKey, String> {
        use num_bigint::BigInt;
        use rayon::prelude::*;

        let base_w = 20u32; // Use base 2^20 for gadget decomposition
        let n = self.params.n;

        // Compute s^2 using GPU NTT
        let s_squared = self.multiply_polynomials_gpu(&sk.coeffs, &sk.coeffs, moduli)?;

        // Determine number of digits needed dynamically
        let q_prod_big: BigInt = moduli.iter().map(|&q| BigInt::from(q)).product();
        let q_bits = q_prod_big.bits() as u32;
        let num_digits = ((q_bits + base_w - 1) / base_w) as usize;

        let mut evk0 = Vec::with_capacity(num_digits);
        let mut evk1 = Vec::with_capacity(num_digits);

        // Precompute B^t mod q for each prime and each digit
        let base = 1u64 << base_w;
        let mut bpow_t_mod_q = vec![vec![0u64; moduli.len()]; num_digits];
        for (j, &q) in moduli.iter().enumerate() {
            let q_u128 = q as u128;
            let mut p = 1u128;
            for t in 0..num_digits {
                bpow_t_mod_q[t][j] = (p % q_u128) as u64;
                p = (p * (base as u128)) % q_u128;
            }
        }

        // Generate evaluation key for each digit (parallelized on CPU, but uses GPU for multiplications)
        for t in 0..num_digits {
            // Compute B^t * s^2
            let bt_s2: Vec<RnsRepresentation> = s_squared
                .iter()
                .map(|rns| {
                    let values: Vec<u64> = rns.values.iter().enumerate()
                        .map(|(j, &val)| {
                            let q = moduli[j];
                            let bt_mod_q = bpow_t_mod_q[t][j];
                            ((val as u128) * (bt_mod_q as u128) % (q as u128)) as u64
                        })
                        .collect();
                    RnsRepresentation::new(values, moduli.to_vec())
                })
                .collect();

            // Sample uniform a_t
            let a_t = self.sample_uniform(moduli);

            // Sample error e_t
            let e_t = self.sample_error(moduli);

            // Compute b_t = -a_t*s + e_t + B^t * s^2 (GPU for a_t*s)
            let a_t_times_s = self.multiply_polynomials_gpu(&a_t, &sk.coeffs, moduli)?;
            let neg_a_t_times_s = self.negate_polynomial(&a_t_times_s, moduli);
            let temp = self.add_polynomials(&neg_a_t_times_s, &e_t);
            let b_t = self.add_polynomials(&temp, &bt_s2);

            evk0.push(a_t);
            evk1.push(b_t);
        }

        Ok(EvaluationKey::new(base_w, evk0, evk1, sk.level))
    }

    /// Negate polynomial (CPU operation, very cheap)
    fn negate_polynomial(
        &self,
        poly: &[RnsRepresentation],
        moduli: &[u64],
    ) -> Vec<RnsRepresentation> {
        poly.iter()
            .map(|rns| {
                let values: Vec<u64> = rns
                    .values
                    .iter()
                    .zip(moduli)
                    .map(|(&val, &q)| if val == 0 { 0 } else { q - val })
                    .collect();
                RnsRepresentation::new(values, moduli.to_vec())
            })
            .collect()
    }

    /// Add two polynomials (CPU operation, very cheap)
    fn add_polynomials(
        &self,
        a: &[RnsRepresentation],
        b: &[RnsRepresentation],
    ) -> Vec<RnsRepresentation> {
        a.iter().zip(b.iter()).map(|(a_rns, b_rns)| a_rns.add(b_rns)).collect()
    }

    /// Find primitive 2n-th root of unity mod q (psi)
    ///
    /// For twisted NTT (negacyclic convolution), we need q ≡ 1 (mod 2n).
    /// Modular multiplication helper
    fn mul_mod(a: u64, b: u64, q: u64) -> u64 {
        ((a as u128 * b as u128) % q as u128) as u64
    }

    /// Returns psi where psi^(2n) ≡ 1 mod q.
    /// Then omega = psi^2 is the n-th root used for standard NTT.
    ///
    /// FIXED: Removed over-constrained quadratic non-residue check and strict psi^n == -1 requirement.
    /// We only need: psi^(2n) = 1 and psi^n ≠ 1 for a primitive 2n-th root.
    fn find_primitive_2n_root(n: usize, q: u64) -> Result<u64, String> {
        // Verify q ≡ 1 (mod 2n)
        let two_n = (2 * n) as u64;
        if (q - 1) % two_n != 0 {
            return Err(format!("q = {} is not NTT-friendly for n = {} (q-1 must be divisible by 2n)", q, n));
        }

        let exp = (q - 1) / two_n;

        // Try small bases first (fast and works in practice)
        for g in [2u64, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31] {
            let psi = Self::pow_mod(g % q, exp, q);
            // Check: psi != 1, psi^(2n) = 1, psi^n != 1
            if psi != 1
                && Self::pow_mod(psi, two_n, q) == 1
                && Self::pow_mod(psi, n as u64, q) != 1
            {
                eprintln!("    Found psi={} from generator g={}", psi, g);
                return Ok(psi);
            }
        }

        // Fallback: more extensive search (increased range for robustness)
        for g in 32u64..20000 {
            let psi = Self::pow_mod(g % q, exp, q);
            if psi != 1
                && Self::pow_mod(psi, two_n, q) == 1
                && Self::pow_mod(psi, n as u64, q) != 1
            {
                eprintln!("    Found psi={} from generator g={}", psi, g);
                return Ok(psi);
            }
        }

        Err(format!("Failed to find primitive root for q = {}, n = {} after 20000 candidates", q, n))
    }

    /// DEPRECATED: Old over-constrained verification - keeping for reference but not used
    #[allow(dead_code)]
    fn is_primitive_root_candidate_old(g: u64, n: usize, q: u64) -> bool {
        // This was TOO STRICT: requiring g to be quadratic non-residue
        // unnecessarily filtered out valid generators
        if Self::pow_mod(g, (q - 1) / 2, q) == 1 {
            return false;
        }

        let psi = Self::pow_mod(g, (q - 1) / (2 * n as u64), q);

        // This was TOO STRICT: requiring psi^n == q-1 exactly
        // We only need psi^n != 1 for primitive 2n-th root
        let psi_n = Self::pow_mod(psi, n as u64, q);
        if psi_n != q - 1 {
            return false;
        }

        let psi_2n = Self::pow_mod(psi, 2 * n as u64, q);
        psi_2n == 1
    }

    /// Check if g is a generator mod q
    fn is_generator(g: u64, q: u64) -> bool {
        // g is a generator if g^((q-1)/p) ≠ 1 for all prime factors p of q-1
        // For our use case, we just check order is q-1
        Self::pow_mod(g, q - 1, q) == 1 && Self::pow_mod(g, (q - 1) / 2, q) != 1
    }

    /// Modular exponentiation: base^exp mod q
    fn pow_mod(mut base: u64, mut exp: u64, q: u64) -> u64 {
        let mut result = 1u64;
        base %= q;

        while exp > 0 {
            if exp & 1 == 1 {
                result = ((result as u128 * base as u128) % q as u128) as u64;
            }
            base = ((base as u128 * base as u128) % q as u128) as u64;
            exp >>= 1;
        }

        result
    }

    /// Get reference to Metal device (for rotation key generation)
    pub fn device(&self) -> &Arc<MetalDevice> {
        &self.device
    }

    /// Get reference to NTT contexts (for rotation key generation)
    pub fn ntt_contexts(&self) -> &[MetalNttContext] {
        &self.ntt_contexts
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_metal_keygen_basic() {
        // Use small parameters for quick test
        let params = CliffordFHEParams::new_test_ntt_1024();

        let mut key_ctx = match MetalKeyContext::new(params.clone()) {
            Ok(ctx) => ctx,
            Err(e) => {
                println!("Skipping test: Metal not available: {}", e);
                return;
            }
        };

        // Generate keys
        let (pk, sk, evk) = key_ctx.keygen().expect("Failed to generate keys");

        // Basic sanity checks
        assert_eq!(pk.a.len(), params.n);
        assert_eq!(sk.coeffs.len(), params.n);
        assert!(evk.evk0.len() > 0, "EvaluationKey should have at least one digit");
        assert_eq!(evk.evk0[0].len(), params.n, "Each evk component should have n coefficients");

        println!("Metal key generation test passed!");
    }
}
